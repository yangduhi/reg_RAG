import asyncio
import json
import re
from typing import Coroutine, List, Dict, Optional, Union, Any

from flashrank import Ranker, RerankRequest
from langchain_community.retrievers import BM25Retriever
from langchain_core.documents import Document
from langchain_core.output_parsers import StrOutputParser
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.retrievers import BaseRetriever
from langchain_classic.retrievers import EnsembleRetriever
from langchain_google_genai import ChatGoogleGenerativeAI

from src.core.config import settings
from src.core.logging import logger
from src.ingestion.pipeline import IngestionPipeline
from src.rag.vectorstore import VectorStoreManager
from src.rag.graph import RAGGraph


class DummyRetriever(BaseRetriever):
    """
    [ì•ˆì „ ìž¥ì¹˜] ë”ë¯¸ ê²€ìƒ‰ê¸° (Dummy Retriever)
    - ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ê°€ ë¹„ì–´ìžˆê±°ë‚˜ ì´ˆê¸°í™” ì‹¤íŒ¨ ì‹œ ì‹œìŠ¤í…œ ì¶©ëŒ(Crash)ì„ ë°©ì§€í•©ë‹ˆë‹¤.
    - ì˜ˆì™¸ë¥¼ ë°œìƒì‹œí‚¤ëŠ” ëŒ€ì‹  ë¹ˆ ë¦¬ìŠ¤íŠ¸ë¥¼ ë°˜í™˜í•˜ì—¬ RAG íŒŒì´í”„ë¼ì¸ì´ ì•ˆì „í•˜ê²Œ ì¢…ë£Œë˜ë„ë¡ í•©ë‹ˆë‹¤.
    """

    def _get_relevant_documents(
        self, query: str, *, run_manager: Any = None
    ) -> List[Document]:
        """ë™ê¸° í˜¸ì¶œ: í•­ìƒ ë¹ˆ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜"""
        return []

    async def _aget_relevant_documents(
        self, query: str, *, run_manager: Any = None
    ) -> List[Document]:
        """ë¹„ë™ê¸° í˜¸ì¶œ: í•­ìƒ ë¹ˆ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜"""
        return []


class RAGEngine:
    """
    [RAG ì—”ì§„ ì½”ì–´] (Retrieval-Augmented Generation Engine)
    
    ì´ í´ëž˜ìŠ¤ëŠ” ì‹œìŠ¤í…œì˜ ë‘ë‡Œ ì—­í• ì„ í•˜ë©°, UIì™€ ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§(ê²€ìƒ‰ ë° ìƒì„±)ì„ ì—°ê²°í•˜ëŠ” íŒŒì‚¬ë“œ(Facade)ìž…ë‹ˆë‹¤.
    
    [ì£¼ìš” ê¸°ëŠ¥]
    1. LLM ë° ë²¡í„° ì €ìž¥ì†Œ ì´ˆê¸°í™”
    2. í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ê¸°(BM25 + Vector) êµ¬ì„± ë° ê´€ë¦¬
    3. LangGraph ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ (Chat)
    4. ë°ì´í„° íŒŒì´í”„ë¼ì¸(ìˆ˜ì§‘/ê°€ê³µ) ì œì–´
    
    Attributes:
        llm (ChatGoogleGenerativeAI): ë‹µë³€ ìƒì„±ì„ ìœ„í•œ Gemini ëª¨ë¸ ì¸ìŠ¤í„´ìŠ¤.
        vstore_manager (VectorStoreManager): ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤(ChromaDB) ì ‘ê·¼ ê´€ë¦¬ìž.
        metadata_cache (Dict): ê·œì • ID, ì œëª©, URL ë“±ì˜ ë©”íƒ€ë°ì´í„°ë¥¼ ì¸ë©”ëª¨ë¦¬ì— ìºì‹±í•˜ì—¬ ë¹ ë¥¸ ì ‘ê·¼ ì§€ì›.
        reranker (Ranker): ê²€ìƒ‰ ê²°ê³¼ì˜ ì •í™•ë„ë¥¼ ë†’ì´ê¸° ìœ„í•œ ìž¬ìˆœìœ„í™”(Reranking) ëª¨ë¸.
        bm25_retriever (BM25Retriever): í‚¤ì›Œë“œ ê¸°ë°˜ ê²€ìƒ‰ê¸° (ì •í™•í•œ ìš©ì–´ ë§¤ì¹­ìš©).
        graph (RAGGraph): LangGraph ê¸°ë°˜ì˜ ê²€ìƒ‰-ìƒì„± ì›Œí¬í”Œë¡œìš° ì •ì˜.
    """

    def __init__(self) -> None:
        """
        ì—”ì§„ ì´ˆê¸°í™”
        - ë™ê¸°ì ìœ¼ë¡œ LLM, DB ë§¤ë‹ˆì €ë¥¼ ì„¤ì •í•˜ê³ ,
        - ë¹„ë™ê¸°ì ìœ¼ë¡œ ê²€ìƒ‰ê¸°(Retriever) ì´ˆê¸°í™” íƒœìŠ¤í¬ë¥¼ ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì‹œìž‘í•©ë‹ˆë‹¤. (UI ë¡œë”© ì§€ì—° ë°©ì§€)
        """
        # 1. LLM ì´ˆê¸°í™” (Google Gemini API ì‚¬ìš©)
        # settings.LLM_MODEL_NAME (ì˜ˆ: gemini-2.0-flash) ëª¨ë¸ ì‚¬ìš© -> ì¼ë°˜/ê³ ì† ìž‘ì—…ìš©
        self.llm = ChatGoogleGenerativeAI(
            model=settings.LLM_MODEL_NAME,
            google_api_key=settings.GOOGLE_API_KEY,
            temperature=settings.LLM_TEMPERATURE,
        )
        
        # settings.LLM_MODEL_SMART (ì˜ˆ: gemini-2.5-pro) ëª¨ë¸ ì‚¬ìš© -> ê³ ì„±ëŠ¥ ë‹µë³€ ìƒì„±ìš©
        self.llm_smart = ChatGoogleGenerativeAI(
            model=settings.LLM_MODEL_SMART,
            google_api_key=settings.GOOGLE_API_KEY,
            temperature=settings.LLM_TEMPERATURE,
        )

        # 2. ë²¡í„° DB ë§¤ë‹ˆì € ì—°ê²° (ë°ì´í„° ì €ìž¥ì†Œ)
        self.vstore_manager = VectorStoreManager()

        # 3. ë©”íƒ€ë°ì´í„° ìºì‹œ ë¡œë“œ (ê·œì • ì •ë³´)
        self.metadata_cache = self._load_all_metadata()

        # 4. í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì»´í¬ë„ŒíŠ¸ (ì´ˆê¸°ê°’ None, ë¹„ë™ê¸° ë¡œë”©)
        self.reranker: Optional[Ranker] = None
        self.bm25_retriever: Optional[BM25Retriever] = None
        self.is_initialized: bool = False
        self.initialization_lock = asyncio.Lock()
        
        # 5. LangGraph ì›Œí¬í”Œë¡œìš° ìƒì„± (selfë¥¼ ì „ë‹¬í•˜ì—¬ ì—”ì§„ì˜ ë¦¬ì†ŒìŠ¤ ê³µìœ )
        self.graph = RAGGraph(self)
        
        # [ì„±ëŠ¥ ìµœì í™”] ê²€ìƒ‰ê¸° ì´ˆê¸°í™”ëŠ” ì‹œê°„ì´ ê±¸ë¦¬ë¯€ë¡œ(ì¸ë±ì‹± ë“±) ë°±ê·¸ë¼ìš´ë“œ íƒœìŠ¤í¬ë¡œ ì‹¤í–‰
        self.initialization_task = asyncio.create_task(self._initialize_retrievers())

    async def _initialize_retrievers(self) -> None:
        """
        [ë¹„ë™ê¸° ì´ˆê¸°í™”] ê²€ìƒ‰ê¸° êµ¬ì„± (BM25 & Reranker)
        
        - ë²¡í„° DBì˜ ëª¨ë“  ë¬¸ì„œë¥¼ ë¡œë“œí•˜ì—¬ BM25(TF-IDF) ì¸ë±ìŠ¤ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
        - Reranker ëª¨ë¸ì„ ë©”ëª¨ë¦¬ì— ë¡œë“œí•©ë‹ˆë‹¤.
        - ì´ ê³¼ì •ì´ ì™„ë£Œë˜ì–´ì•¼ ì •ìƒì ì¸ ê²€ìƒ‰ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.
        """
        try:
            logger.info("â³ ê²€ìƒ‰ê¸°(Retriever) ì´ˆê¸°í™” ë° ì¸ë±ì‹± ì‹œìž‘...")
            # DB I/OëŠ” ë¸”ë¡œí‚¹ ìž‘ì—…ì´ë¯€ë¡œ ë³„ë„ ìŠ¤ë ˆë“œì—ì„œ ì‹¤í–‰í•˜ì—¬ ì´ë²¤íŠ¸ ë£¨í”„ ì°¨ë‹¨ ë°©ì§€
            all_docs = await asyncio.to_thread(self.vstore_manager.get_all_documents)

            if all_docs:
                # 1. BM25 ê²€ìƒ‰ê¸° ì´ˆê¸°í™” (í‚¤ì›Œë“œ ê²€ìƒ‰ìš© ì—­ìƒ‰ì¸ ìƒì„±)
                logger.info(f"ðŸ› ï¸ BM25 ê²€ìƒ‰ê¸° ì¸ë±ì‹± ì¤‘... (ë¬¸ì„œ ìˆ˜: {len(all_docs)}ê°œ)")
                self.bm25_retriever = await asyncio.to_thread(
                    BM25Retriever.from_documents, all_docs
                )
                logger.info("âœ… BM25 ì¸ë±ì‹± ì™„ë£Œ.")

                # 2. Reranker ëª¨ë¸ ë¡œë“œ (ìž¬ìˆœìœ„í™”ìš© Cross-Encoder)
                # FlashRank ë¼ì´ë¸ŒëŸ¬ë¦¬ ì‚¬ìš© (ê²½ëŸ‰í™”ëœ BERT ëª¨ë¸)
                logger.info(f"ðŸš€ Reranker ëª¨ë¸ ë¡œë”©: {settings.RERANKER_MODEL}")
                self.reranker = await asyncio.to_thread(
                    Ranker, model_name=settings.RERANKER_MODEL, cache_dir="/tmp/flashrank_cache"
                )
                logger.info("âœ… Reranker ì´ˆê¸°í™” ì™„ë£Œ.")
                self.is_initialized = True
            else:
                logger.warning("âš ï¸ DBê°€ ë¹„ì–´ìžˆìŠµë‹ˆë‹¤. ê²€ìƒ‰ê¸°ë¥¼ ì´ˆê¸°í™”í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. (ë°ì´í„° ìˆ˜ì§‘ í•„ìš”)")
                self.bm25_retriever = None
                self.reranker = None

        except Exception as e:
            logger.error(f"âŒ ê²€ìƒ‰ê¸° ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            self.bm25_retriever = None
            self.reranker = None
    
    @property
    def vector_store(self):
        """ë‚´ë¶€ VectorStore(ChromaDB) ê°ì²´ ì ‘ê·¼ìž"""
        return self.vstore_manager.db

    def get_retrievers(
        self, k: Optional[int] = None, use_mmr: bool = False, filter_std: str = "All"
    ) -> List[BaseRetriever]:
        """
        [ê²€ìƒ‰ê¸° íŒ©í† ë¦¬] ìƒí™©ì— ë§žëŠ” ê²€ìƒ‰ê¸° ëª©ë¡ ë°˜í™˜
        
        í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰(Hybrid Search)ì„ ìœ„í•´ BM25ì™€ Vector Retrieverë¥¼ ë¦¬ìŠ¤íŠ¸ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤.
        LangGraphì˜ 'retrieve' ë…¸ë“œì—ì„œ ì´ë¥¼ ë³‘ë ¬ë¡œ ì‹¤í–‰í•©ë‹ˆë‹¤.

        Args:
            k (int): ê²€ìƒ‰í•  ë¬¸ì„œ ìˆ˜ (ê¸°ë³¸ê°’: ì„¤ì •íŒŒì¼ì˜ RETRIEVER_K = 25)
            use_mmr (bool): MMR(Maximal Marginal Relevance) ì•Œê³ ë¦¬ì¦˜ ì‚¬ìš© ì—¬ë¶€.
                            (ìœ ì‚¬í•˜ë©´ì„œë„ ë‹¤ì–‘í•œ ë‚´ìš©ì„ ì°¾ê¸° ìœ„í•´ True ê¶Œìž¥)
            filter_std (str): íŠ¹ì • ê·œì • IDë¡œ í•„í„°ë§í•  ê²½ìš° ì‚¬ìš© (í˜„ìž¬ëŠ” "All"ë¡œ ì „ì²´ ê²€ìƒ‰)

        Returns:
            List[BaseRetriever]: [BM25Retriever, VectorRetriever]
        """
        _k = k if k is not None else settings.RETRIEVER_K

        if not self.bm25_retriever:
            logger.error("âŒ ê²€ìƒ‰ê¸°ê°€ ì¤€ë¹„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return [DummyRetriever()]

        # 1. ë²¡í„° ê²€ìƒ‰ ì„¤ì • (Semantic Search)
        # Reranking íš¨ê³¼ë¥¼ ê·¹ëŒ€í™”í•˜ê¸° ìœ„í•´ ìµœì¢… í•„ìš”í•œ ê°œìˆ˜(K)ë³´ë‹¤ ë” ë§Žì€ í›„ë³´êµ°(3ë°°ìˆ˜)ì„ 1ì°¨ë¡œ ê²€ìƒ‰í•©ë‹ˆë‹¤.
        search_type = "mmr" if use_mmr else "similarity"
        candidate_k = _k * 3

        search_kwargs = {"k": candidate_k}
        if use_mmr:
            search_kwargs["fetch_k"] = candidate_k * 2 # MMR í›„ë³´í’€ í¬ê¸°

        # (ì„ íƒì‚¬í•­) ë©”íƒ€ë°ì´í„° í•„í„°ë§
        if filter_std and filter_std != "All":
            search_kwargs["filter"] = {"standard_id": filter_std}

        vector_retriever = self.vstore_manager.db.as_retriever(
            search_type=search_type, search_kwargs=search_kwargs
        )

        return [self.bm25_retriever, vector_retriever]

    # ... (get_ensemble_retrieverëŠ” í˜„ìž¬ ì‚¬ìš©ë˜ì§€ ì•Šì§€ë§Œ í•˜ìœ„ í˜¸í™˜ì„±ì„ ìœ„í•´ ìœ ì§€) ...

    async def chat(
        self, 
        user_question: str, 
        chat_history: List[Dict] = None,
        search_regions: List[str] = None,
        similarity_threshold: float = 0.5
    ) -> Dict:
        """
        [ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜] ì‚¬ìš©ìž ì§ˆë¬¸ ì²˜ë¦¬ ë° ë‹µë³€ ìƒì„±
        
        UIì—ì„œ í˜¸ì¶œë˜ëŠ” ì§„ìž…ì ìœ¼ë¡œ, ë‹¤ìŒ ê³¼ì •ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤:
        1. ì—”ì§„ ì´ˆê¸°í™” ëŒ€ê¸° (ê²€ìƒ‰ê¸° ì¤€ë¹„ í™•ì¸)
        2. LangGraph ì›Œí¬í”Œë¡œìš°(Graph) ì‹¤í–‰
        3. ê²°ê³¼(ë‹µë³€ ë° ê·¼ê±° ë¬¸ì„œ) ë°˜í™˜

        Args:
            user_question (str): ì‚¬ìš©ìž ì§ˆë¬¸.
            chat_history (List[Dict]): ì´ì „ ëŒ€í™” ë‚´ì—­ (ë©€í‹°í„´ ëŒ€í™” ì§€ì›ìš©, í˜„ìž¬ëŠ” ì£¼ë¡œ ë‹¨ì¼í„´).
            search_regions (List[str]): ê²€ìƒ‰í•  ì§€ì—­ í•„í„° (ì˜ˆ: ["FMVSS", "KMVSS"]). UI ì²´í¬ë°•ìŠ¤ì™€ ì—°ë™.
            similarity_threshold (float): ê²€ìƒ‰ ë¯¼ê°ë„(ì •í™•ë„) ì„¤ì •. UI ìŠ¬ë¼ì´ë”ì™€ ì—°ë™.

        Returns:
            Dict: {"generation": ë‹µë³€ í…ìŠ¤íŠ¸, "documents": [ì°¸ê³  ë¬¸ì„œ ë¦¬ìŠ¤íŠ¸]}
        """
        # ê²€ìƒ‰ê¸° ì´ˆê¸°í™”ê°€ ì™„ë£Œë  ë•Œê¹Œì§€ ëŒ€ê¸° (Thread-safe)
        async with self.initialization_lock:
            if not self.is_initialized:
                await self.initialization_task

        # LangGraph ì›Œí¬í”Œë¡œìš° ì‹¤í–‰
        try:
            return await self.graph.run(
                user_question, 
                chat_history=chat_history,
                search_regions=search_regions,
                similarity_threshold=similarity_threshold
            )
        except Exception as e:
            logger.error(f"LangGraph ì‹¤í–‰ ì¤‘ ì¹˜ëª…ì  ì˜¤ë¥˜: {e}", exc_info=True)
            return {
                "generation": "ì£„ì†¡í•©ë‹ˆë‹¤. ì‹œìŠ¤í…œ ì˜¤ë¥˜ê°€ ë°œìƒí•˜ì—¬ ë‹µë³€ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê´€ë¦¬ìžì—ê²Œ ë¬¸ì˜í•´ì£¼ì„¸ìš”.",
                "documents": [],
            }

    async def run_pipeline(self, force_refresh: bool = False) -> str:
        """
        [ë°ì´í„° íŒŒì´í”„ë¼ì¸ íŠ¸ë¦¬ê±°] ë°ì´í„° ìˆ˜ì§‘ ë° ê°€ê³µ í”„ë¡œì„¸ìŠ¤ ì‹¤í–‰
        
        UIì˜ 'ë°ì´í„°ë² ì´ìŠ¤ ê´€ë¦¬' ë²„íŠ¼ì„ í†µí•´ í˜¸ì¶œë©ë‹ˆë‹¤.
        1. IngestionPipeline ì‹¤í–‰ (í¬ë¡¤ë§ -> íŒŒì‹± -> ì²­í‚¹ -> ìž„ë² ë”© -> ì €ìž¥)
        2. ë³€ê²½ ì‚¬í•­ì´ ìžˆì„ ê²½ìš° ê²€ìƒ‰ê¸°(BM25/Reranker) ìž¬ì´ˆê¸°í™”

        Args:
            force_refresh (bool): Trueì¼ ê²½ìš° ê¸°ì¡´ DBë¥¼ ì‚­ì œí•˜ê³  ì²˜ìŒë¶€í„° ë‹¤ì‹œ êµ¬ì¶•.
        """
        try:
            logger.info("ðŸ”„ ë°ì´í„° íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì‹œìž‘...")
            pipeline = IngestionPipeline()
            await pipeline.run(force_refresh=force_refresh)

            # ë©”íƒ€ë°ì´í„° ìºì‹œ ê°±ì‹ 
            self.metadata_cache = self._load_all_metadata()
            
            logger.info("ðŸ”„ ë°ì´í„° ë³€ê²½ ê°ì§€: ê²€ìƒ‰ ì—”ì§„ì„ ë‹¤ì‹œ ë¡œë“œí•©ë‹ˆë‹¤.")
            # ìƒˆ ë°ì´í„°ë¥¼ ë°˜ì˜í•˜ê¸° ìœ„í•´ ê²€ìƒ‰ê¸° ìž¬ì´ˆê¸°í™” íƒœìŠ¤í¬ ì‹œìž‘
            self.initialization_task = asyncio.create_task(self._initialize_retrievers())
            await self.initialization_task

            return "âœ… ë°ì´í„° ì²˜ë¦¬ ë° ì—”ì§„ ì—…ë°ì´íŠ¸ê°€ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!"
        except Exception as e:
            logger.error(f"íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì˜¤ë¥˜: {e}", exc_info=True)
            raise

    # ... (Helper ë©”ì„œë“œë“¤: ë©”íƒ€ë°ì´í„° ì¡°íšŒ ë“±) ...
    def get_available_standards(self) -> List[str]:
        """DBì— ì¡´ìž¬í•˜ëŠ” ê·œì • ID ëª©ë¡ ë°˜í™˜"""
        ids = list(self.metadata_cache.keys())
        # ìˆ«ìž ê¸°ì¤€ ì •ë ¬ ë¡œì§ (ì˜ˆ: FMVSS 108 -> 108 ì¶”ì¶œ)
        def sort_key(k: str) -> int:
            nums = re.findall(r"(\d+)", str(k))
            return int(nums[0]) if nums else 9999
        return sorted(list(set(ids)), key=sort_key)

    def _load_all_metadata(self) -> Dict[str, dict]:
        """ì—¬ëŸ¬ ì†ŒìŠ¤(JSON)ì—ì„œ ë©”íƒ€ë°ì´í„°ë¥¼ ë¡œë“œí•˜ì—¬ í†µí•©"""
        merged = {}
        # ìš°ì„ ìˆœìœ„: KMVSS -> ECE -> FMVSS -> í†µí•© ë ˆì§€ìŠ¤íŠ¸ë¦¬
        candidates = [
            settings.DATA_DIR / "metadata_kmvss.json",
            settings.DATA_DIR / "metadata_ece.json",
            settings.DATA_DIR / "metadata_fmvss.json",
            settings.METADATA_FILE,
        ]
        for path in candidates:
            if path.exists():
                try:
                    with open(path, "r", encoding="utf-8") as f:
                        data = json.load(f)
                        if isinstance(data, list):
                            for item in data:
                                key = str(item.get("id", item.get("num", "")))
                                if key:
                                    merged[key] = {
                                        "title": item.get("title", ""),
                                        "url": item.get("web_url") or item.get("source_url"),
                                    }
                        elif isinstance(data, dict):
                            merged.update(data)
                except Exception:
                    pass
        return merged
