import asyncio
import json
import re
from typing import Coroutine, List, Dict, Optional, Union, Any

from flashrank import Ranker, RerankRequest
from langchain_community.retrievers import BM25Retriever
from langchain_core.documents import Document
from langchain_core.output_parsers import StrOutputParser
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.retrievers import BaseRetriever
from langchain_classic.retrievers import EnsembleRetriever
from langchain_google_genai import ChatGoogleGenerativeAI

from src.core.config import settings
from src.core.logging import logger
from src.ingestion.pipeline import IngestionPipeline
from src.rag.vectorstore import VectorStoreManager
from src.rag.graph import RAGGraph


class DummyRetriever(BaseRetriever):
    """
    ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ê°€ ë¹„ì–´ìˆì„ ë•Œ ì‹œìŠ¤í…œ ì¶©ëŒì„ ë°©ì§€í•˜ê¸° ìœ„í•œ ë”ë¯¸ ê²€ìƒ‰ê¸°(Retriever) êµ¬í˜„ì²´ì…ë‹ˆë‹¤.

    ì´ˆê¸°í™” ì‹¤íŒ¨ë‚˜ ë°ì´í„° ë¶€ì¬ ì‹œ ì˜ˆì™¸ë¥¼ ë°œìƒì‹œí‚¤ëŠ” ëŒ€ì‹  ë¹ˆ ë¦¬ìŠ¤íŠ¸ë¥¼ ë°˜í™˜í•˜ì—¬
    RAG íŒŒì´í”„ë¼ì¸ì´ ì•ˆì „í•˜ê²Œ ë™ì‘í•˜ë„ë¡ ë³´ì¥í•˜ëŠ” ì•ˆì „ì¥ì¹˜ ì—­í• ì„ í•©ë‹ˆë‹¤.
    """

    def _get_relevant_documents(
        self, query: str, *, run_manager: Any = None
    ) -> List[Document]:
        """
        ë™ê¸° ë°©ì‹ ë¬¸ì„œ ê²€ìƒ‰ êµ¬í˜„ (í•­ìƒ ë¹ˆ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜).

        Args:
            query (str): ê²€ìƒ‰ ì¿¼ë¦¬.
            run_manager (Any, optional): ì‹¤í–‰ ì½œë°± ê´€ë¦¬ì.

        Returns:
            List[Document]: í•­ìƒ ë¹ˆ ë¦¬ìŠ¤íŠ¸ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
        """
        return []

    async def _aget_relevant_documents(
        self, query: str, *, run_manager: Any = None
    ) -> List[Document]:
        """
        ë¹„ë™ê¸° ë°©ì‹ ë¬¸ì„œ ê²€ìƒ‰ êµ¬í˜„ (í•­ìƒ ë¹ˆ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜).

        Args:
            query (str): ê²€ìƒ‰ ì¿¼ë¦¬.
            run_manager (Any, optional): ì‹¤í–‰ ì½œë°± ê´€ë¦¬ì.

        Returns:
            List[Document]: í•­ìƒ ë¹ˆ ë¦¬ìŠ¤íŠ¸ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
        """
        return []


class RAGEngine:
    """
    í•µì‹¬ RAG(Retrieval-Augmented Generation, ê²€ìƒ‰ ì¦ê°• ìƒì„±) ì—”ì§„ í´ë˜ìŠ¤ì…ë‹ˆë‹¤.

    ì´ í´ë˜ìŠ¤ëŠ” ì‚¬ìš©ì ì¸í„°í˜ì´ìŠ¤(UI)ì™€ ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§ì„ ì—°ê²°í•˜ëŠ” íŒŒì‚¬ë“œ(Facade) ì—­í• ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.
    ë‹¤ìŒê³¼ ê°™ì€ ì „ì²´ RAG íŒŒì´í”„ë¼ì¸ì„ ì¡°ìœ¨í•©ë‹ˆë‹¤:
    1. ì¿¼ë¦¬ ì²˜ë¦¬ ë° ë³€í™˜ (Query Transformation)
    2. í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ (ë²¡í„° ê²€ìƒ‰ + í‚¤ì›Œë“œ ê²€ìƒ‰)
    3. ì¬ìˆœìœ„í™” (Reranking, Cross-encoder/FlashRank í™œìš©)
    4. ë‹µë³€ ìƒì„± (LLM í™œìš©)

    Attributes:
        llm (ChatGoogleGenerativeAI): ì–¸ì–´ ëª¨ë¸ ì¸ìŠ¤í„´ìŠ¤ (Gemini).
        vstore_manager (VectorStoreManager): ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ ê´€ë¦¬ì.
        metadata_cache (Dict[str, dict]): ê·œì • ë©”íƒ€ë°ì´í„°ì˜ ì¸ë©”ëª¨ë¦¬ ìºì‹œ.
        reranker (Optional[Ranker]): ì¬ìˆœìœ„í™” ëª¨ë¸ ì¸ìŠ¤í„´ìŠ¤ (FlashRank).
        bm25_retriever (Optional[BM25Retriever]): í‚¤ì›Œë“œ ê¸°ë°˜ ê²€ìƒ‰ê¸° ì¸ìŠ¤í„´ìŠ¤.
        is_initialized (bool): ê²€ìƒ‰ê¸° ì´ˆê¸°í™” ì™„ë£Œ ì—¬ë¶€ í”Œë˜ê·¸.
    """

    def __init__(self) -> None:
        """
        RAGEngineì„ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.

        LLM, ë²¡í„° ì €ì¥ì†Œ ê´€ë¦¬ì, ë©”íƒ€ë°ì´í„° ìºì‹œë¥¼ ì„¤ì •í•©ë‹ˆë‹¤.
        ê²€ìƒ‰ê¸°(BM25, Reranker)ì˜ ë¹„ë™ê¸° ì´ˆê¸°í™” ì‘ì—…ì„ ì‹œì‘í•©ë‹ˆë‹¤.
        """
        # 1. LLM ì´ˆê¸°í™” (Gemini)
        self.llm = ChatGoogleGenerativeAI(
            model=settings.LLM_MODEL_NAME,
            google_api_key=settings.GOOGLE_API_KEY,
            temperature=settings.LLM_TEMPERATURE,
        )

        # 2. ë²¡í„° DB ë§¤ë‹ˆì € ì—°ê²°
        self.vstore_manager = VectorStoreManager()

        # 3. ë©”íƒ€ë°ì´í„° ìºì‹œ ë¡œë“œ
        self.metadata_cache = self._load_all_metadata()

        # 4. í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™”
        self.reranker: Optional[Ranker] = None
        self.bm25_retriever: Optional[BM25Retriever] = None
        self.is_initialized: bool = False
        self.initialization_lock = asyncio.Lock()
        
        # 5. LangGraph ì›Œí¬í”Œë¡œìš° ì´ˆê¸°í™” (selfë¥¼ ì „ë‹¬í•˜ì—¬ ì—”ì§„ ê¸°ëŠ¥ ê³µìœ )
        self.graph = RAGGraph(self)
        
        # ë°±ê·¸ë¼ìš´ë“œ ì´ˆê¸°í™” ì‘ì—… ì‹œì‘
        self.initialization_task: Coroutine = self._initialize_retrievers()

    async def _initialize_retrievers(self) -> None:
        """
        ê²€ìƒ‰ ì»´í¬ë„ŒíŠ¸(BM25, Reranker)ë¥¼ ë¹„ë™ê¸°ì ìœ¼ë¡œ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.

        ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ì— ë¬¸ì„œê°€ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤. ë°ì´í„°ê°€ ìˆëŠ” ê²½ìš°,
        Non-blocking ìŠ¤ë ˆë“œì—ì„œ BM25 ì¸ë±ìŠ¤ë¥¼ ìƒì„±í•˜ê³  Reranker ëª¨ë¸ì„ ë¡œë“œí•©ë‹ˆë‹¤.
        
        Raises:
            Exception: ì´ˆê¸°í™” ì¤‘ ë°œìƒí•˜ëŠ” ëª¨ë“  ì˜¤ë¥˜ë¥¼ ë¡œê·¸ë¡œ ê¸°ë¡í•©ë‹ˆë‹¤.
        """
        try:
            logger.info("â³ ê²€ìƒ‰ê¸°(Retriever) ì´ˆê¸°í™” ì¤‘...")
            # ë¸”ë¡œí‚¹ DB í˜¸ì¶œì„ ë³„ë„ ìŠ¤ë ˆë“œì—ì„œ ì‹¤í–‰
            all_docs = await asyncio.to_thread(self.vstore_manager.get_all_documents)

            if all_docs:
                # BM25 ê²€ìƒ‰ê¸° ì´ˆê¸°í™” (Non-blocking)
                logger.info("ğŸ› ï¸ BM25 ê²€ìƒ‰ê¸° ì¸ë±ì‹± ì‹œì‘...")
                self.bm25_retriever = await asyncio.to_thread(
                    BM25Retriever.from_documents, all_docs
                )
                logger.info(
                    f"âœ… BM25 ì¸ë±ì‹± ì™„ë£Œ (ë¬¸ì„œ ìˆ˜: {len(all_docs)}ê°œ)"
                )

                # Reranker ì´ˆê¸°í™” (Non-blocking)
                logger.info(f"ğŸš€ Reranker ëª¨ë¸ ì´ˆê¸°í™” ì¤‘: {settings.RERANKER_MODEL}")
                self.reranker = await asyncio.to_thread(
                    Ranker, model_name=settings.RERANKER_MODEL, cache_dir="/tmp/flashrank_cache"
                )
                logger.info("âœ… Reranker ì´ˆê¸°í™” ì™„ë£Œ.")
                self.is_initialized = True
            else:
                logger.warning("âš ï¸ DBê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤. ê²€ìƒ‰ê¸°ë¥¼ ì´ˆê¸°í™”í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                self.bm25_retriever = None
                self.reranker = None

        except Exception as e:
            logger.error(f"âŒ ê²€ìƒ‰ê¸° ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            self.bm25_retriever = None
            self.reranker = None
    
    @property
    def vector_store(self):
        """ë‚´ë¶€ VectorStore ì¸ìŠ¤í„´ìŠ¤ì— ì ‘ê·¼í•©ë‹ˆë‹¤."""
        return self.vstore_manager.db

    def get_retrievers(
        self, k: Optional[int] = None, use_mmr: bool = False, filter_std: str = "All"
    ) -> List[BaseRetriever]:
        """
        í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ì— ì‚¬ìš©í•  ê²€ìƒ‰ê¸° ëª©ë¡ì„ ìƒì„±í•©ë‹ˆë‹¤.

        Args:
            k (Optional[int]): ê²€ìƒ‰í•  ë¬¸ì„œ ìˆ˜. ê¸°ë³¸ê°’ì€ settings.RETRIEVER_K.
            use_mmr (bool): ë‹¤ì–‘ì„± í™•ë³´ë¥¼ ìœ„í•œ MMR(Maximal Marginal Relevance) ì‚¬ìš© ì—¬ë¶€.
            filter_std (str): í•„í„°ë§í•  ê·œì • ID (ì˜ˆ: "FMVSS 108"). ê¸°ë³¸ê°’ì€ "All".

        Returns:
            List[BaseRetriever]: [BM25Retriever, VectorRetriever] ë¦¬ìŠ¤íŠ¸ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
        """
        _k = k if k is not None else settings.RETRIEVER_K

        if not self.bm25_retriever:
            logger.error("âŒ ê²€ìƒ‰ê¸°ê°€ ì¤€ë¹„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return [DummyRetriever()]

        # 1. ë²¡í„° ê²€ìƒ‰ ì„¤ì • (í›„ë³´êµ° í™•ì¥)
        # ì¬ìˆœìœ„í™”(Reranking)ë¥¼ ìœ„í•´ ìµœì¢… ê°œìˆ˜ë³´ë‹¤ ë” ë§ì€ í›„ë³´ë¥¼ 1ì°¨ë¡œ ê²€ìƒ‰í•©ë‹ˆë‹¤.
        search_type = "mmr" if use_mmr else "similarity"
        candidate_k = _k * 3

        search_kwargs = {"k": candidate_k}
        if use_mmr:
            search_kwargs["fetch_k"] = candidate_k * 2

        if filter_std and filter_std != "All":
            search_kwargs["filter"] = {"standard_id": filter_std}

        vector_retriever = self.vstore_manager.db.as_retriever(
            search_type=search_type, search_kwargs=search_kwargs
        )

        return [self.bm25_retriever, vector_retriever]

    def get_ensemble_retriever(
        self, k: Optional[int] = None, use_mmr: bool = False, filter_std: str = "All"
    ) -> BaseRetriever:
        """
        ì‚¬ì „ ì„¤ì •ëœ ì•™ìƒë¸” ê²€ìƒ‰ê¸°(EnsembleRetriever, BM25 + Vector)ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.

        Args:
            k (Optional[int]): ê²€ìƒ‰í•  ë¬¸ì„œ ìˆ˜.
            use_mmr (bool): MMR ì‚¬ìš© ì—¬ë¶€.
            filter_std (str): í•„í„°ë§í•  ê·œì • ID.

        Returns:
            BaseRetriever: í‚¤ì›Œë“œì™€ ì˜ë¯¸ ê¸°ë°˜ ê²€ìƒ‰ì´ ê²°í•©ëœ EnsembleRetriever ì¸ìŠ¤í„´ìŠ¤.
        """
        _k = k if k is not None else settings.RETRIEVER_K

        if not self.bm25_retriever:
            logger.error("âŒ ê²€ìƒ‰ê¸°ê°€ ì¤€ë¹„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return DummyRetriever()

        # 1. ë²¡í„° ê²€ìƒ‰ ì„¤ì •
        search_type = "mmr" if use_mmr else "similarity"
        candidate_k = _k * 3

        search_kwargs = {"k": candidate_k}
        if use_mmr:
            search_kwargs["fetch_k"] = candidate_k * 2

        if filter_std and filter_std != "All":
            search_kwargs["filter"] = {"standard_id": filter_std}

        vector_retriever = self.vstore_manager.db.as_retriever(
            search_type=search_type, search_kwargs=search_kwargs
        )

        # 2. ì•™ìƒë¸” ìƒì„± (BM25 50%, Vector 50% ê°€ì¤‘ì¹˜)
        ensemble_retriever = EnsembleRetriever(
            retrievers=[self.bm25_retriever, vector_retriever], weights=[0.5, 0.5]
        )

        return ensemble_retriever

    async def transform_query(self, original_query: str) -> str:
        """
        ì‚¬ìš©ì ì¿¼ë¦¬ë¥¼ ë³€í™˜í•˜ì—¬ ê²€ìƒ‰ ìµœì í™”ë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤.

        ì´ ë©”ì„œë“œëŠ” "ì¿¼ë¦¬ í™•ì¥(Query Expansion)" ë‹¨ê³„ë¡œ ë™ì‘í•©ë‹ˆë‹¤.
        LLMì„ ì‚¬ìš©í•˜ì—¬ ë‹¤ìŒì„ ìˆ˜í–‰í•©ë‹ˆë‹¤:
        1. í•œêµ­ì–´ ê¸°ìˆ  ìš©ì–´ -> ì˜ì–´ í‚¤ì›Œë“œ ë³€í™˜ (Global Regulation ê²€ìƒ‰ìš©)
        2. í•œêµ­ì–´ ë™ì˜ì–´ ë° ë„ì–´ì“°ê¸° ë³€í˜• ìƒì„± (í•œêµ­ì–´ ê²€ìƒ‰ ì •í™•ë„ í–¥ìƒìš©)

        Args:
            original_query (str): ì‚¬ìš©ìì˜ ì›ë³¸ ì§ˆë¬¸.

        Returns:
            str: í™•ì¥ëœ ì¿¼ë¦¬ ë¬¸ìì—´.
        """
        try:
            prompt = ChatPromptTemplate.from_template(
                """
                You are an expert in Automotive Safety Regulations (FMVSS, KMVSS, ECE).
                Your task is to expand the user's search query to improve retrieval recall.

                Please generate:
                1. **English Keywords**: Translate technical terms into English (for FMVSS/ECE).
                2. **Korean Variations**: Generate synonyms, spacing variations, and related terms for Korean keywords (for KMVSS).
                   - Example: "ë³´í–‰ìë³´í˜¸" -> "ë³´í–‰ì ë³´í˜¸", "ë³´í–‰ìì•ˆì „"
                   - Example: "ë°©í–¥ì§€ì‹œë“±" -> "ë°©í–¥ ì§€ì‹œë“±", "í„´ ì‹œê·¸ë„"

                Output ONLY the additional keywords separated by spaces. Do not repeat the original query.

                User Question: {question}
                Expanded Keywords:"""
            )
            chain = prompt | self.llm | StrOutputParser()
            expanded_keywords = await chain.ainvoke({"question": original_query})
            
            # ì›ë³¸ ì¿¼ë¦¬ì™€ í™•ì¥ëœ í‚¤ì›Œë“œ ê²°í•©
            final_query = f"{original_query} {expanded_keywords.strip()}"
            logger.info(f"ğŸ”¥ [ì¿¼ë¦¬ í™•ì¥] ìµœì¢…: '{final_query}'")
            return final_query
        except Exception as e:
            logger.error(f"ì¿¼ë¦¬ ë³€í™˜ ì˜¤ë¥˜: {e}")
            return original_query

    async def chat(self, user_question: str) -> str:
        """
        RAG íŒŒì´í”„ë¼ì¸ì˜ ë©”ì¸ ì§„ì…ì ì…ë‹ˆë‹¤.
        LangGraph ì›Œí¬í”Œë¡œìš°ë¥¼ ì‹¤í–‰í•˜ì—¬ ë‹µë³€ì„ ìƒì„±í•©ë‹ˆë‹¤.

        Args:
            user_question (str): ì‚¬ìš©ìì˜ ì§ˆë¬¸.

        Returns:
            str: LLMì´ ìƒì„±í•œ ë‹µë³€.
        """
        async with self.initialization_lock:
            if not self.is_initialized:
                await self.initialization_task

        # LangGraph ì‹¤í–‰
        try:
            return await self.graph.run(user_question)
        except Exception as e:
            logger.error(f"LangGraph ì‹¤í–‰ ì˜¤ë¥˜: {e}", exc_info=True)
            return "ì£„ì†¡í•©ë‹ˆë‹¤. ì‹œìŠ¤í…œ ì˜¤ë¥˜ê°€ ë°œìƒí•˜ì—¬ ë‹µë³€ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

    async def run_pipeline(self, force_refresh: bool = False) -> str:
        """
        ë°ì´í„° ìˆ˜ì§‘ íŒŒì´í”„ë¼ì¸ì„ ìˆ˜ë™ìœ¼ë¡œ ì‹¤í–‰í•©ë‹ˆë‹¤.

        Args:
            force_refresh (bool): Trueì¼ ê²½ìš°, ë³€ê²½ ì‚¬í•­ê³¼ ê´€ê³„ì—†ì´ ëª¨ë“  íŒŒì¼ì„ ë‹¤ì‹œ ì²˜ë¦¬í•©ë‹ˆë‹¤.

        Returns:
            str: ì™„ë£Œ ìƒíƒœ ë©”ì‹œì§€.

        Raises:
            Exception: íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ ì‹œ ì˜ˆì™¸ë¥¼ ì „íŒŒí•©ë‹ˆë‹¤.
        """
        try:
            logger.info("ğŸ”„ ë°ì´í„° íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì‹œì‘...")
            pipeline = IngestionPipeline()
            await pipeline.run(force_refresh=force_refresh)

            self.metadata_cache = self._load_all_metadata()
            logger.info("ğŸ”„ ë°ì´í„° ë³€ê²½ ê°ì§€: ê²€ìƒ‰ ì—”ì§„ì„ ë‹¤ì‹œ ë¡œë“œí•©ë‹ˆë‹¤.")
            # ìƒˆ ë°ì´í„°ë¥¼ ë°˜ì˜í•˜ê¸° ìœ„í•´ ê²€ìƒ‰ê¸° ì¬ì´ˆê¸°í™”
            self.initialization_task = self._initialize_retrievers()
            await self.initialization_task

            return "âœ… ë°ì´í„° ì²˜ë¦¬ ë° ì—”ì§„ ì—…ë°ì´íŠ¸ ì™„ë£Œ!"
        except Exception as e:
            logger.error(f"íŒŒì´í”„ë¼ì¸ ì˜¤ë¥˜: {e}", exc_info=True)
            raise

    def get_available_standards(self) -> List[str]:
        """
        ì‚¬ìš© ê°€ëŠ¥í•œ ê·œì • ID ëª©ë¡ì„ ì •ë ¬í•˜ì—¬ ë°˜í™˜í•©ë‹ˆë‹¤ (ì˜ˆ: "108", "201").

        Returns:
            List[str]: ì •ë ¬ëœ ID ë¦¬ìŠ¤íŠ¸.
        """
        ids = list(self.metadata_cache.keys())

        def sort_key(k: str) -> int:
            nums = re.findall(r"(\d+)", str(k))
            return int(nums[0]) if nums else 9999

        return sorted(list(set(ids)), key=sort_key)

    def get_metadata_title(self, standard_id: str) -> str:
        """ì£¼ì–´ì§„ ê·œì • IDì— í•´ë‹¹í•˜ëŠ” ì œëª©ì„ ë°˜í™˜í•©ë‹ˆë‹¤."""
        return self.metadata_cache.get(str(standard_id), {}).get("title", "")

    def get_web_url(self, standard_id: str) -> Optional[str]:
        """ì£¼ì–´ì§„ ê·œì • IDì˜ ì›ë¬¸ ì›¹ URLì„ ë°˜í™˜í•©ë‹ˆë‹¤."""
        return self.metadata_cache.get(str(standard_id), {}).get("url")

    def _load_all_metadata(self) -> Dict[str, dict]:
        """
        ì—¬ëŸ¬ JSON ì†ŒìŠ¤ì—ì„œ ë©”íƒ€ë°ì´í„°ë¥¼ ë¡œë“œí•˜ê³  ë³‘í•©í•©ë‹ˆë‹¤.

        Returns:
            Dict[str, dict]: ê·œì • IDë¥¼ í‚¤ë¡œ í•˜ëŠ” ë©”íƒ€ë°ì´í„° ë”•ì…”ë„ˆë¦¬.
        """
        merged = {}
        candidates = [
            settings.DATA_DIR / "metadata_kmvss.json",
            settings.DATA_DIR / "metadata_ece.json",
            settings.DATA_DIR / "metadata_fmvss.json",
            settings.METADATA_FILE,
        ]
        for path in candidates:
            if path.exists():
                try:
                    with open(path, "r", encoding="utf-8") as f:
                        data = json.load(f)
                        if isinstance(data, list):
                            for item in data:
                                key = str(item.get("id", item.get("num", "")))
                                if key:
                                    merged[key] = {
                                        "title": item.get("title", ""),
                                        "url": item.get("web_url")
                                        or item.get("source_url"),
                                    }
                        elif isinstance(data, dict):
                            merged.update(data)
                except Exception:
                    # ê²¬ê³ ì„±ì„ ìœ„í•´ ê°œë³„ ë©”íƒ€ë°ì´í„° íŒŒì¼ ì˜¤ë¥˜ëŠ” ë¬´ì‹œí•©ë‹ˆë‹¤.
                    pass
        return merged
